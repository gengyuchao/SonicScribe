import os
import time
import logging
import asyncio
from config import AppConfig
from data_basic import AudioChunk, SpeechSegment
from typing import Optional, List, Tuple
from audio_manager import AudioBufferManager
from vad import VADProcessor
import torch
import numpy as np
from models_manager import asr_model_get, vad_model_get

logger = logging.getLogger("speech-to-text")

# ======================
# VAD å¤„ç†å™¨ 
# ======================
class VADProcessorManager:
    """VADå¤„ç†ç®¡ç†å™¨ï¼ŒæŒ‰10ä¸ªç‰‡æ®µç»„åˆè¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹"""
    def __init__(self, buffer_manager: AudioBufferManager):
        self.buffer_manager = buffer_manager
        self.vad_is_speaking = False
        self.speech_start_chunk_id = -1
        self.speech_start_time = -1.0
        self.silence_count = 0
        self.speech_count = 0
        self.last_processed_chunk_id = -1
        self.last_vad_time = time.time()
        self.processing_window = AppConfig.VAD_PROCESS_WINDOW  # ç»„åˆ10ä¸ªç‰‡æ®µè¿›è¡ŒVADæ£€æµ‹
        self.chunk_accumulator = []  # ç”¨äºç´¯ç§¯ç‰‡æ®µ
        self.vad_processor = vad_model_get()
    
    async def process_vad(self) -> Tuple[bool, Optional[int], Optional[int]]:
        """
        å¢å¼ºç‰ˆVADå¤„ç† - æŒ‰10ä¸ªç‰‡æ®µç»„åˆå¤„ç†
        è¿”å›: (çŠ¶æ€å˜åŒ–, è¯­éŸ³å¼€å§‹ç‰‡æ®µID, è¯­éŸ³ç»“æŸç‰‡æ®µID)
        """
        # è®°å½•VADå¤„ç†é—´éš”
        current_time = time.time()
        self.last_vad_time = current_time
        
        # è·å–å¾…å¤„ç†çš„ç‰‡æ®µ - åªè·å–æœªå¤„ç†çš„ç‰‡æ®µ
        recent_chunks = self.buffer_manager.get_chunks_for_vad()
        
        # è°ƒè¯•ï¼šè®°å½•ç¼“å†²åŒºçŠ¶æ€
        if not recent_chunks:
            logger.debug(f"ğŸ” æ— æ–°éŸ³é¢‘ç‰‡æ®µç”¨äºVADå¤„ç†ï¼Œæœ€åå¤„ç†ç‰‡æ®µID: {self.last_processed_chunk_id}")
            return False, None, None
        
        # æ›´æ–°æœ€åå¤„ç†çš„ç‰‡æ®µID
        if recent_chunks[-1].chunk_id > self.last_processed_chunk_id:
            self.last_processed_chunk_id = recent_chunks[-1].chunk_id
        
        # ç´¯ç§¯ç‰‡æ®µ
        for chunk in recent_chunks:
            if chunk.chunk_id not in [c.chunk_id for c in self.chunk_accumulator]:
                self.chunk_accumulator.append(chunk)

        # æ£€æŸ¥æ˜¯å¦ç´¯ç§¯äº†è¶³å¤Ÿçš„ç‰‡æ®µ
        if len(self.chunk_accumulator) < self.processing_window:
            logger.debug(f"â³ ç­‰å¾…æ›´å¤šç‰‡æ®µç”¨äºVADå¤„ç†ï¼Œå½“å‰: {len(self.chunk_accumulator)}/{self.processing_window}")
            return False, None, None
        
        # ç¡®ä¿ç‰‡æ®µæŒ‰æ—¶é—´é¡ºåºæ’åˆ—
        self.chunk_accumulator.sort(key=lambda x: x.chunk_id)
        
        logger.debug(f"ğŸ” å¼€å§‹VADå¤„ç†ï¼Œç‰‡æ®µIDèŒƒå›´: {self.chunk_accumulator[0].chunk_id}-{self.chunk_accumulator[-1].chunk_id}")
        
        state_changed = False
        speech_start_id = None
        speech_end_id = None
        
        try:
            # ç»„åˆ10ä¸ªç‰‡æ®µçš„éŸ³é¢‘æ•°æ®
            combined_audio = bytearray()
            for chunk in self.chunk_accumulator[:self.processing_window]:
                combined_audio.extend(chunk.audio_data)
            
            # è½¬æ¢ä¸ºtensorè¿›è¡ŒVADå¤„ç†
            audio_array = np.frombuffer(bytes(combined_audio), dtype=np.int16)
            if len(audio_array) == 0:
                logger.warning("âš ï¸ æ— æ•ˆéŸ³é¢‘æ•°æ®ï¼Œè·³è¿‡VADå¤„ç†")
                self.chunk_accumulator = self.chunk_accumulator[self.processing_window:]
                return False, None, None
            
            logger.debug(f"ğŸ”Š å¤„ç†VADç»„åˆæ•°æ®ï¼Œæ€»æ ·æœ¬æ•°: {len(audio_array)}, ç‰‡æ®µæ•°: {self.processing_window}")
            
            audio_array = audio_array.copy()
            audio_tensor = torch.tensor(audio_array, dtype=torch.float32)
            audio_tensor = audio_tensor / 32768.0

            is_speech = self.vad_processor.is_voice_active(audio_tensor.squeeze(), threshold=AppConfig.VAD_SPEECH_THRESHOLD)
            
            if is_speech:
                self.speech_count += 1
                self.speech_count = min(self.speech_count, AppConfig.VAD_SMOOTHING_WINDOW)
                self.silence_count = 0
            else:
                self.silence_count += 1
                self.silence_count = min(self.silence_count, AppConfig.VAD_SMOOTHING_WINDOW)
                self.speech_count = max(0, self.speech_count - 1)
            
            # ç¡®ä¿è®¡æ•°æ˜¯æ•´æ•°
            self.speech_count = int(self.speech_count)
            self.silence_count = int(self.silence_count)
            
            # æ£€æµ‹çŠ¶æ€å˜åŒ–
            logger.debug(f"ğŸ™ï¸self.vad_is_speaking: {self.vad_is_speaking} - è¯­éŸ³è®¡æ•°: {self.speech_count} é™éŸ³è®¡æ•°: {self.silence_count} ")
            # æ£€æµ‹è¯­éŸ³å¼€å§‹
            if not self.vad_is_speaking and self.speech_count >= 1:
                self.vad_is_speaking = True
                self.speech_start_chunk_id = self.chunk_accumulator[0].chunk_id
                self.speech_start_time = self.chunk_accumulator[0].timestamp
                speech_start_id = self.chunk_accumulator[0].chunk_id
                state_changed = True
                logger.info(f"ğŸ™ï¸ è¯­éŸ³å¼€å§‹æ£€æµ‹ï¼Œç»„åˆç‰‡æ®µID: {speech_start_id}-{self.chunk_accumulator[-1].chunk_id} è¯­éŸ³è®¡æ•°: {self.speech_count}")
        
            # æ£€æµ‹è¯­éŸ³ç»“æŸ
            elif self.vad_is_speaking and self.silence_count >= AppConfig.VAD_SMOOTHING_WINDOW:
                self.vad_is_speaking = False
                speech_end_id = self.chunk_accumulator[-1].chunk_id
                state_changed = True
                logger.info(f"â¹ï¸ è¯­éŸ³ç»“æŸæ£€æµ‹ï¼Œç»„åˆç‰‡æ®µID: {self.chunk_accumulator[0].chunk_id}-{speech_end_id} é™éŸ³è®¡æ•°: {self.silence_count}")
            
            # æ¸…é™¤å·²å¤„ç†çš„ç‰‡æ®µ
            self.chunk_accumulator = self.chunk_accumulator[self.processing_window:]
            
        except Exception as e:
            logger.error(f"âŒ VADç»„åˆå¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
            # æ¸…é™¤ç¼“å†²åŒºä»¥é¿å…å¡ä½
            self.chunk_accumulator = []
        
        return state_changed, speech_start_id, speech_end_id
    
    def is_speaking_state(self) -> bool:
        """è·å–å½“å‰VADçŠ¶æ€"""
        return self.vad_is_speaking

