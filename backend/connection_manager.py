import os
import time
import logging
import asyncio
import math
from fastapi import WebSocket
from starlette.websockets import WebSocketState
from typing import Optional, List, Tuple
from config import AppConfig
from vad import VADProcessor
from debug import DebugAudioManager
from audio_manager import AudioBufferManager
from data_basic import AudioChunk, SpeechSegment
from vad_processor_manager import VADProcessorManager
from transcription_manager import TranscriptionManager

logger = logging.getLogger("speech-to-text")


# ======================
# ConnectionManager 
# ======================
class ConnectionManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨ï¼Œåè°ƒVADå’Œè½¬å½•å¤„ç†"""
    def __init__(self, websocket: WebSocket, client_id: str):
        self.websocket = websocket
        self.client_id = client_id
        self.buffer_manager = AudioBufferManager()
        self.vad_processor = VADProcessorManager(self.buffer_manager)
        self.transcription_manager = TranscriptionManager()
        self.last_activity = time.time()
        self.is_active = True
        self.vad_task: Optional[asyncio.Task] = None
        self.last_temporary_transcription_time = 0.0
        self.last_chunk_id = -1
        self.saved_temporary_transcription_text = ""
        
    async def start_vad_processing(self):
        """å¯åŠ¨ç‹¬ç«‹çš„VADå¤„ç†ä»»åŠ¡"""
        if self.vad_task is not None and not self.vad_task.done():
            logger.warning(f"âš ï¸ VAD ä»»åŠ¡å·²åœ¨è¿è¡Œï¼Œå®¢æˆ·ç«¯: {self.client_id}")
            return
            
        async def vad_loop():
            logger.info(f"ğŸ”„ VAD å¤„ç†å¾ªç¯å¼€å§‹ï¼Œå®¢æˆ·ç«¯: {self.client_id}")
            last_vad_run = time.time()
            
            while self.is_active:
                try:
                    current_time = time.time()
                    elapsed = current_time - last_vad_run
                    
                    # ç¡®ä¿VADå¤„ç†ä¸ä¼šè¿‡äºé¢‘ç¹
                    if elapsed < AppConfig.VAD_PROCESSING_INTERVAL_MS / 1000.0:
                        await asyncio.sleep((AppConfig.VAD_PROCESSING_INTERVAL_MS / 1000.0) - elapsed)
                    
                    last_vad_run = time.time()
                    
                    # å¤„ç†VAD
                    state_changed, speech_start_id, speech_end_id = await self.vad_processor.process_vad()
                    
                    user_speaking = self.vad_processor.is_speaking_state()

                    if user_speaking:
                        logger.debug(f"ğŸ™ï¸ VAD çŠ¶æ€: è¯­éŸ³æ´»åŠ¨, å®¢æˆ·ç«¯: {self.client_id}")
                    
                    if state_changed:
                        # è¯­éŸ³å¼€å§‹
                        if speech_start_id is not None and user_speaking:
                            segment = self.buffer_manager.create_speech_segment(
                                speech_start_id, 
                                self.buffer_manager.chunk_buffer[speech_start_id].timestamp
                            )
                            logger.info(f"ğŸ¤ è¯­éŸ³æ®µå¼€å§‹ï¼ŒID: {speech_start_id}, å®¢æˆ·ç«¯: {self.client_id}")
                        
                        # è¯­éŸ³ç»“æŸ
                        if speech_end_id is not None and not user_speaking:
                            segment = self.buffer_manager.finalize_current_segment(
                                speech_end_id,
                                self.buffer_manager.chunk_buffer[speech_end_id].timestamp
                            )
                            logger.info(f"ğŸ¤ è¯­éŸ³æ®µç»“æŸï¼ŒID: {speech_end_id}, å®¢æˆ·ç«¯: {self.client_id}")
                            if segment:
                                self.saved_temporary_transcription_text = ""
                                await self.process_committed_transcription(segment)
                    
                    # å®šæœŸå¤„ç†ä¸´æ—¶è½¬å½•
                    current_time = time.time()
                    if (user_speaking and 
                        current_time - self.last_temporary_transcription_time >= 1.0):
                        await self.process_temporary_transcription()
                        self.last_temporary_transcription_time = current_time
                    
                    # å°ç¡ä»¥è®©å‡ºäº‹ä»¶å¾ªç¯
                    await asyncio.sleep(0.01)
                    
                except asyncio.CancelledError:
                    logger.info(f"â¹ï¸ VAD å¤„ç†å¾ªç¯è¢«å–æ¶ˆï¼Œå®¢æˆ·ç«¯: {self.client_id}")
                    break
                except Exception as e:
                    logger.error(f"âŒ VADå¤„ç†å¾ªç¯é”™è¯¯: {str(e)}\n{traceback.format_exc()}, å®¢æˆ·ç«¯: {self.client_id}")
                    # å‡ºé”™åä¼‘æ¯æ›´é•¿æ—¶é—´
                    await asyncio.sleep(1.0)
        
        self.vad_task = asyncio.create_task(vad_loop())
        logger.info(f"âœ… VAD å¤„ç†ä»»åŠ¡å·²åˆ›å»ºï¼Œå®¢æˆ·ç«¯: {self.client_id}")
    
    async def process_audio_chunk(self, audio_data: bytes, debug_audio: Optional[DebugAudioManager] = None):
        """å¤„ç†å•ä¸ªéŸ³é¢‘ç‰‡æ®µ"""
        try:
            if debug_audio:
                debug_audio.write(audio_data)
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            chunk = self.buffer_manager.add_audio_chunk(audio_data)
            self.last_chunk_id = chunk.chunk_id
            self.last_activity = time.time()
            
            # è°ƒè¯•ï¼šè®°å½•å¤„ç†çŠ¶æ€
            if chunk.chunk_id % 5 == 0:  # æ¯5ä¸ªç‰‡æ®µè®°å½•ä¸€æ¬¡
                logger.debug(f"ğŸ“Š éŸ³é¢‘ç‰‡æ®µ {chunk.chunk_id} å·²å¤„ç†, ç¼“å†²åŒºå¤§å°: {len(self.buffer_manager.chunk_buffer)}, å®¢æˆ·ç«¯: {self.client_id}")
        
        except Exception as e:
            logger.error(f"âŒ å¤„ç†éŸ³é¢‘ç‰‡æ®µå¤±è´¥: {str(e)}\n{traceback.format_exc()}, å®¢æˆ·ç«¯: {self.client_id}")
            raise
    
    async def process_temporary_transcription(self):
        """å¤„ç†ä¸´æ—¶è½¬å½•"""
        if not self.vad_processor.is_speaking_state() or not self.buffer_manager.current_segment:
            return
        
        try:
            # è·å–å½“å‰è¯­éŸ³æ®µçš„æœ€æ–°ç‰‡æ®µ
            chunks = self.buffer_manager.get_temporary_transcription_chunks()
            if not chunks:
                return
            
            # åˆå¹¶éŸ³é¢‘æ•°æ®
            audio_data = b''.join(chunk.audio_data for chunk in chunks)
            
            # æ‰§è¡Œä¸´æ—¶è½¬å½•
            transcript = await self.transcription_manager.transcribe_temporary(audio_data)
            if not transcript:
                return
            
            self.saved_temporary_transcription_text += transcript

            # å‘é€ä¸´æ—¶ç»“æœ
            current_time = time.time()
            await self.send_json({
                "type": "tentative_output",
                "current_text": transcript,
                "text": self.saved_temporary_transcription_text,
                "start_chunk_id": chunks[0].chunk_id,
                "end_chunk_id": chunks[-1].chunk_id,
                "duration": len(chunks) * AppConfig.AUDIO_CHUNK_DURATION_MS / 1000.0,
                "timestamp": current_time,
                "client_id": self.client_id,
                "confidence": "tentative",
                "processing_delay": current_time - chunks[-1].timestamp
            })
            
            logger.debug(f"âš¡ ä¸´æ—¶è½¬å½•: '{transcript[:50]}...', ç‰‡æ®µ: {chunks[0].chunk_id}-{chunks[-1].chunk_id}")
            
        except Exception as e:
            logger.error(f"âŒ ä¸´æ—¶è½¬å½•å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
    
    
    async def process_committed_transcription(self, segment: SpeechSegment):
        """å¤„ç†ç¡®è®¤è½¬å½•ï¼šæ”¯æŒè¶…é•¿éŸ³é¢‘è‡ªåŠ¨åˆ†æ®µè½¬å½•"""
        try:
            audio_data = self.buffer_manager.get_committed_audio_data(segment)
            print(f"audio_data len ï¼š {len(audio_data)}")
            
            if len(audio_data) < AppConfig.AUDIO_CHUNK_SIZE * 2:  # è‡³å°‘200ms
                logger.warning(f"âš ï¸ éŸ³é¢‘æ®µå¤ªçŸ­ ({len(audio_data)} bytes)ï¼Œè·³è¿‡ç¡®è®¤è½¬å½•")
                return

            sample_rate = AppConfig.AUDIO_SAMPLE_RATE
            bytes_per_sec = sample_rate * 2
            max_duration = AppConfig.MAX_SEGMENT_DURATION
            max_bytes = int(max_duration * bytes_per_sec)

            # è®¡ç®—å®é™…éŸ³é¢‘æ—¶é•¿ï¼ˆç”¨äºæ ¡éªŒï¼‰
            actual_duration = len(audio_data) / bytes_per_sec
            segment_duration = min(actual_duration, segment.duration)  # ä»¥é˜² metadata ä¸å‡†

            # å¦‚æœæœªè¶…é™ï¼Œèµ°åŸé€»è¾‘
            if segment_duration <= max_duration:
                transcript = await self.transcription_manager.transcribe_committed(audio_data, segment_duration)
                if not transcript:
                    logger.warning("âš ï¸ ç¡®è®¤è½¬å½•ç»“æœä¸ºç©º")
                    return
                segment.transcript = transcript
                await self._send_committed_result(
                    transcript=transcript,
                    segment=segment,
                    audio_length=len(audio_data),
                    duration=segment_duration
                )
                logger.info(f"âœ… ç¡®è®¤è½¬å½•æˆåŠŸ: '{transcript[:100]}...', æ—¶é•¿: {segment_duration:.2f}s")
                return

            # === è¶…é•¿å¤„ç†ï¼šåˆ†æ®µ ===
            logger.info(f"âœ‚ï¸ éŸ³é¢‘æ®µè¿‡é•¿ ({segment_duration:.2f}s)ï¼Œæ‹†åˆ†ä¸ºå¤šä¸ªå­æ®µï¼ˆæ¯æ®µâ‰¤{max_duration}sï¼‰")
            num_subsegments = math.ceil(len(audio_data) / max_bytes)
            sub_results: List[Tuple[str, float, float]] = []  # (text, start, end)

            for i in range(num_subsegments):
                start_byte = i * max_bytes
                end_byte = min(start_byte + max_bytes, len(audio_data))
                sub_audio = audio_data[start_byte:end_byte]
                sub_duration = len(sub_audio) / bytes_per_sec

                # è®¡ç®—å­æ®µçš„æ—¶é—´æˆ³ï¼ˆåŸºäºåŸå§‹ segment çš„ start_timeï¼‰
                sub_start_time = segment.start_time + i * max_duration
                sub_end_time = sub_start_time + sub_duration

                # è½¬å½•å­æ®µ
                transcript = await self.transcription_manager.transcribe_committed(sub_audio, sub_duration)
                if not transcript:
                    logger.warning(f"âš ï¸ å­æ®µ {i+1}/{num_subsegments} è½¬å½•ç»“æœä¸ºç©º")
                    # ä»ç»§ç»­å¤„ç†å…¶ä»–ç‰‡æ®µï¼Œä¸ä¸­æ–­
                    continue

                # å‘é€å­æ®µç»“æœ
                await self._send_committed_result(
                    transcript=transcript,
                    segment=segment,
                    audio_length=len(sub_audio),
                    duration=sub_duration,
                    custom_start_time=sub_start_time,
                    custom_end_time=sub_end_time,
                    suffix=f"_part_{i+1}"
                )
                sub_results.append((transcript, sub_start_time, sub_end_time))

            # å¯é€‰ï¼šæ‹¼æ¥å®Œæ•´æ–‡æœ¬å¹¶æ›´æ–° segmentï¼ˆå¦‚æœéœ€è¦ï¼‰
            full_transcript = " ".join(t for t, _, _ in sub_results)
            segment.transcript = full_transcript

            logger.info(f"âœ… è¶…é•¿éŸ³é¢‘åˆ†æ®µè½¬å½•å®Œæˆ ({len(sub_results)} æ®µ)ï¼Œæ€»æ–‡æœ¬: '{full_transcript[:100]}...'")

        except Exception as e:
            logger.error(f"âŒ ç¡®è®¤è½¬å½•å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")

    async def _send_committed_result(
        self,
        transcript: str,
        segment: SpeechSegment,
        audio_length: int,
        duration: float,
        custom_start_time: float = None,
        custom_end_time: float = None,
        suffix: str = ""
    ):
        """å¤ç”¨å‘é€é€»è¾‘"""
        start_time = custom_start_time if custom_start_time is not None else segment.start_time
        end_time = custom_end_time if custom_end_time is not None else segment.end_time
        seg_id = f"{id(segment)}{suffix}" if suffix else id(segment)

        current_time = time.time()
        await self.send_json({
            "type": "committed_output",
            "text": transcript,
            "segment_id": seg_id,
            "start_chunk_id": segment.start_chunk_id,
            "end_chunk_id": segment.end_chunk_id,
            "start_time": start_time,
            "end_time": end_time,
            "duration": duration,
            "timestamp": current_time,
            "client_id": self.client_id,
            "confidence": "high",
            "audio_length": audio_length
        })
    
    async def send_json(self, data: dict):
        """å®‰å…¨å‘é€JSONæ¶ˆæ¯"""
        try:
            if self.websocket.client_state != WebSocketState.DISCONNECTED:
                await self.websocket.send_json(data)
        except Exception as e:
            logger.warning(f"âš ï¸ æ¶ˆæ¯å‘é€å¤±è´¥ (å®¢æˆ·ç«¯: {self.client_id}): {str(e)}")
            self.is_active = False
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.is_active = False
        
        # å–æ¶ˆVADä»»åŠ¡
        if self.vad_task:
            try:
                self.vad_task.cancel()
            except:
                pass
        
        # æ¸…ç†ç¼“å†²åŒº
        self.buffer_manager.cleanup()
        
        logger.info(f"ğŸ§¹ è¿æ¥ç®¡ç†å™¨æ¸…ç†å®Œæˆï¼Œå®¢æˆ·ç«¯: {self.client_id}")

