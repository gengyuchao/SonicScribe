import os
import time
from contextlib import asynccontextmanager
from typing import Optional, Dict, Any, AsyncGenerator, List, Tuple, Deque
import asyncio
import json
import logging
import traceback
import wave
import torch
import numpy as np
from collections import deque
import uvicorn
from fastapi import FastAPI, UploadFile, File, WebSocket, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from asr import ASRModel
from vad import VADProcessor
from vad_processor_manager import VADProcessorManager
from config import AppConfig
from debug import DebugAudioManager
from connection_manager import ConnectionManager, SpeechSegment, AudioChunk, AudioBufferManager
from utils import convert_audio_to_wav, audiosegment_to_tensor, standardize_audio_tensor
from dotenv import load_dotenv
from models_manager import asr_model_init, vad_model_init, asr_model_get, vad_model_get
from starlette.websockets import WebSocketDisconnect, WebSocketState

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, AppConfig.LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("speech-to-text")


# ======================
# ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ======================
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator:
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")
    # åˆå§‹åŒ–è°ƒè¯•ç›®å½•
    _init_debug_directory()
    # åˆå§‹åŒ–æ¨¡å‹
    await _init_models()
    yield
    # æ¸…ç†èµ„æº
    await _cleanup_resources()

async def _init_models():
    """åˆå§‹åŒ–ASRå’ŒVADæ¨¡å‹"""
    global asr_model, vad_processor
    try:
        logger.info("ğŸ”Š åŠ è½½ VAD å¤„ç†å™¨...")
        vad_model_init()
        vad_processor = vad_model_get()
        logger.info("âœ… VAD å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        logger.info(f"ğŸ§  åŠ è½½ ASR æ¨¡å‹ï¼Œè·¯å¾„: {AppConfig.CHECKPOINT_PATH}, è®¾å¤‡: {AppConfig.DEVICE}")
        asr_model_init()
        asr_model = asr_model_get()
        logger.info("âœ… ASR æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(status_code=503, detail="æ¨¡å‹åŠ è½½å¤±è´¥")

def _init_debug_directory():
    """åˆå§‹åŒ–è°ƒè¯•éŸ³é¢‘ç›®å½•"""
    if AppConfig.DEBUG_AUDIO_ENABLED:
        os.makedirs(AppConfig.DEBUG_AUDIO_BASE_DIR, exist_ok=True)
        logger.info(f"ğŸ“ è°ƒè¯•éŸ³é¢‘å·²å¯ç”¨ï¼Œå­˜å‚¨ç›®å½•: {AppConfig.DEBUG_AUDIO_BASE_DIR}")

async def _cleanup_resources():
    """æ¸…ç†èµ„æº"""
    logger.info("ğŸ§¹ åº”ç”¨å…³é—­ï¼Œæ¸…ç†èµ„æº...")
    global asr_model, vad_processor
    if asr_model and hasattr(asr_model, 'model'):
        logger.info("ğŸ—‘ï¸ é‡Šæ”¾ ASR æ¨¡å‹å†…å­˜...")
        del asr_model.model
        torch.cuda.empty_cache()
        asr_model = None
    vad_processor = None
    logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")

# ======================
# åº”ç”¨åˆå§‹åŒ–
# ======================
app = FastAPI(
    title="è¯­éŸ³è½¬æ–‡å­—API",
    description="åŸºäºFastAPIçš„è¯­éŸ³è½¬æ–‡å­—æœåŠ¡ï¼Œæ”¯æŒå®æ—¶å¯¹è¯å’Œæ–‡ä»¶åˆ†æ",
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    contact={
        "name": "æŠ€æœ¯æ”¯æŒ",
        "email": "gengyuchao11@163.com"
    }
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)


@app.get("/vad/status")
async def get_vad_status():
    """è·å–VADå¤„ç†å™¨çŠ¶æ€ï¼Œç”¨äºè°ƒè¯•"""
    global vad_processor
    
    if not vad_processor:
        return {"status": "error", "message": "VADå¤„ç†å™¨æœªåˆå§‹åŒ–"}
    
    status = {
        "status": "active",
        "processor_type": type(vad_processor).__name__,
        "has_is_voice_active": hasattr(vad_processor, 'is_voice_active'),
        "configuration": {
            "speech_threshold": AppConfig.VAD_SPEECH_THRESHOLD,
            "smoothing_window": AppConfig.VAD_SMOOTHING_WINDOW,
        }
    }
    
    # å°è¯•æµ‹è¯•VADå¤„ç†å™¨
    try:
        test_audio = torch.randn(1600) * 0.01  # å°å¹…éšæœºå™ªå£°
        is_speech = vad_processor.is_voice_active(test_audio)
        status["test_is_speech"] = bool(is_speech)
    except Exception as e:
        status["test_error"] = str(e)
    
    return status


# ======================
# API ç«¯ç‚¹
# ======================
class VADConfig(BaseModel):
    enabled: bool = True
    speech_threshold: float = 0.6
    silence_threshold: float = 0.3
    smoothing_window: int = 2

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "ok",
        "service": "speech-to-text",
        "version": "2.0.0",
        "timestamp": time.time(),
        "models": {
            "asr_loaded": asr_model is not None,
            "vad_loaded": vad_processor is not None
        },
        "configuration": {
            "audio_chunk_duration_ms": AppConfig.AUDIO_CHUNK_DURATION_MS,
            "vad_smoothing_window": AppConfig.VAD_SMOOTHING_WINDOW,
            "max_audio_buffer_seconds": AppConfig.MAX_AUDIO_BUFFER_SECONDS,
            "temporary_transcription_interval": AppConfig.TEMPORARY_TRANSCRIPTION_INTERVAL
        }
    }

@app.get("/debug/config")
async def get_config():
    """è·å–å½“å‰é…ç½®ä¿¡æ¯"""
    return {
        "api_base_url": f"http://{AppConfig.HOST}:{AppConfig.PORT}",
        "websocket_url": f"ws://{AppConfig.HOST}:{AppConfig.PORT}/ws/audio",
        "audio_processing": {
            "chunk_duration_ms": AppConfig.AUDIO_CHUNK_DURATION_MS,
            "chunk_size_bytes": AppConfig.AUDIO_CHUNK_SIZE,
            "max_buffer_seconds": AppConfig.MAX_AUDIO_BUFFER_SECONDS
        },
        "vad_configuration": {
            "smoothing_window": AppConfig.VAD_SMOOTHING_WINDOW,
            "speech_threshold": AppConfig.VAD_SPEECH_THRESHOLD,
            "processing_interval_ms": AppConfig.VAD_PROCESSING_INTERVAL_MS
        },
        "transcription_configuration": {
            "temporary_interval_chunks": AppConfig.TEMPORARY_TRANSCRIPTION_INTERVAL,
            "max_segment_duration": AppConfig.MAX_SEGMENT_DURATION,
        }
    }


@app.post("/transcribe/file")
async def transcribe_file(
    file: UploadFile = File(...),
    stream: bool = True,
    vad_enabled: bool = True
):
    """
    ä¼˜åŒ–ç‰ˆæ–‡ä»¶è½¬æ–‡å­—æ¥å£ï¼ˆæ€§èƒ½æå‡ï¼‰
    """
    if not asr_model or not vad_processor:
        logger.error("ASR æˆ– VAD æ¨¡å‹æœªåŠ è½½")
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½")

    try:
        logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶ä¸Šä¼ : {file.filename}, å¤§å°: {file.size} bytes")
        file_content = await file.read()
        logger.info("ğŸ”„ è½¬æ¢éŸ³é¢‘æ ¼å¼...")
        
        # ä»å†…å­˜ç›´æ¥å¤„ç†ï¼Œé¿å…ä¸´æ—¶æ–‡ä»¶ I/O
        start_time = time.time()
        
        # === ä¼˜åŒ–1: ç›´æ¥ä»å†…å­˜åŠ è½½éŸ³é¢‘ï¼ˆé¿å…æ–‡ä»¶ I/Oï¼‰===
        logger.info("âš¡ ä»å†…å­˜åŠ è½½éŸ³é¢‘...")
        
        # å…ˆè·å–å®Œæ•´éŸ³é¢‘ç”¨äº VAD å’Œåˆ†æ®µ
        try:
            # ä½¿ç”¨å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®
            audio = convert_audio_to_wav(file_content, file.filename)
            full_audio_tensor = audiosegment_to_tensor(audio)
            full_audio_tensor = standardize_audio_tensor(full_audio_tensor)
            
            # ç¡®ä¿æ˜¯ 1D å¼ é‡
            if full_audio_tensor.ndim > 1:
                full_audio_tensor = full_audio_tensor.squeeze()
            
            total_samples = full_audio_tensor.shape[0]
            sample_rate = AppConfig.AUDIO_SAMPLE_RATE
            total_duration = total_samples / sample_rate
            
            logger.info(f"ğŸµ éŸ³é¢‘ä¿¡æ¯ - æ—¶é•¿: {total_duration:.2f}ç§’, æ ·æœ¬æ•°: {total_samples}, é‡‡æ ·ç‡: {sample_rate}Hz")
            logger.info(f"âš¡ éŸ³é¢‘åŠ è½½è€—æ—¶: {time.time() - start_time:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {str(e)}")
            raise HTTPException(status_code=500, detail=f"éŸ³é¢‘åŠ è½½å¤±è´¥: {str(e)}")
        
        # === ä¼˜åŒ–2: å¼‚æ­¥ VAD å¤„ç† + å¿«é€Ÿå“åº” ===
        async def get_segments():
            """å¼‚æ­¥è·å–è¯­éŸ³æ®µï¼Œå°½å¿«è¿”å›æ®µä¿¡æ¯"""
            if not vad_enabled or total_duration < 1.0:  # çŸ­éŸ³é¢‘ä¸ VAD
                logger.info("âš¡ çŸ­éŸ³é¢‘æˆ– VAD ç¦ç”¨ï¼Œä½¿ç”¨æ•´ä¸ªéŸ³é¢‘")
                return [{
                    'original_index': 1,
                    'start_sample': 0,
                    'end_sample': total_samples,
                    'start_time': 0.0,
                    'end_time': total_duration,
                    'duration': total_duration,
                    'is_long_segment': total_duration > AppConfig.MAX_SEGMENT_DURATION
                }]
            
            try:
                logger.info("âš¡ å¼‚æ­¥ VAD æ£€æµ‹ä¸­...")
                vad_start_time = time.time()
                
                # åœ¨åå°çº¿ç¨‹æ‰§è¡Œ CPU å¯†é›†å‹ VAD æ“ä½œ
                loop = asyncio.get_event_loop()
                speech_timestamps, has_speech = await loop.run_in_executor(
                    None, 
                    lambda: vad_processor.detect_voice_activity(
                        full_audio_tensor.unsqueeze(0),  # ç¡®ä¿ç»´åº¦æ­£ç¡®
                        threshold=AppConfig.VAD_SPEECH_THRESHOLD
                    )
                )
                
                vad_time = time.time() - vad_start_time
                logger.info(f"âš¡ VAD æ£€æµ‹å®Œæˆï¼Œè€—æ—¶: {vad_time:.2f}s")
                
                if has_speech and speech_timestamps:
                    segments = []
                    for idx, ts in enumerate(speech_timestamps):
                        start_sample = max(0, min(ts['start'], total_samples - 1))
                        end_sample = max(start_sample + 100, min(ts['end'], total_samples))
                        duration = (end_sample - start_sample) / sample_rate
                        
                        if duration > 0.1:  # è·³è¿‡è¿‡çŸ­æ®µ
                            segments.append({
                                'original_index': idx + 1,
                                'start_sample': start_sample,
                                'end_sample': end_sample,
                                'start_time': start_sample / sample_rate,
                                'end_time': end_sample / sample_rate,
                                'duration': duration,
                                'is_long_segment': duration > AppConfig.MAX_SEGMENT_DURATION
                            })
                    
                    if segments:
                        logger.info(f"âœ… æ£€æµ‹åˆ° {len(segments)} ä¸ªæœ‰æ•ˆè¯­éŸ³æ®µ")
                        return segments
                
                logger.warning("ğŸ”‡ VAD æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œä½¿ç”¨æ•´ä¸ªéŸ³é¢‘")
                return [{
                    'original_index': 1,
                    'start_sample': 0,
                    'end_sample': total_samples,
                    'start_time': 0.0,
                    'end_time': total_duration,
                    'duration': total_duration,
                    'is_long_segment': total_duration > AppConfig.MAX_SEGMENT_DURATION
                }]
                
            except Exception as e:
                logger.error(f"âŒ VAD å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
                logger.warning("ğŸ”‡ VAD å¤±è´¥ï¼Œå›é€€åˆ°æ•´ä¸ªéŸ³é¢‘")
                return [{
                    'original_index': 1,
                    'start_sample': 0,
                    'end_sample': total_samples,
                    'start_time': 0.0,
                    'end_time': total_duration,
                    'duration': total_duration,
                    'is_long_segment': total_duration > AppConfig.MAX_SEGMENT_DURATION
                }]
        
        # === ä¼˜åŒ–3: å°½å¿«è¿”å›æ®µä¿¡æ¯ï¼Œåå°å¤„ç†è½¬å½• ===
        raw_segments = await get_segments()
        
        # åˆ‡å‰²é•¿æ®µ
        final_segments = cut_long_segments(raw_segments, sample_rate, total_samples, total_duration)
        
        # ä¸ºæ‰€æœ‰æ®µåˆ†é…å”¯ä¸€ç´¢å¼•
        for i, segment in enumerate(final_segments):
            segment['segment_index'] = i + 1
        
        total_segments = len(final_segments)
        logger.info(f"ğŸ¯ æœ€ç»ˆå¤„ç† {total_segments} ä¸ªè¯­éŸ³æ®µ")
        
        # === ä¼˜åŒ–4: ç«‹å³è¿”å›æ®µä¿¡æ¯ï¼Œè½¬å½•åœ¨åå°è¿›è¡Œ ===
        async def transcribe_generator():
            """ç”Ÿæˆå™¨ï¼šå¿«é€Ÿè¿”å›æ®µä¿¡æ¯ï¼Œåå°å¼‚æ­¥è½¬å½•"""
            
            # ç«‹å³å‘é€åˆå§‹åŒ–ä¿¡æ¯
            init_message = {
                "type": "initialization",
                "filename": file.filename,
                "file_size": len(file_content),
                "total_duration": round(total_duration, 2),
                "total_segments": total_segments,
                "vad_enabled": vad_enabled,
                "max_segment_duration": AppConfig.MAX_SEGMENT_DURATION,
                "timestamp": time.time()
            }
            yield (json.dumps(init_message, ensure_ascii=False) + "\n").encode("utf-8")
            
            # ç«‹å³å‘é€æ®µæ‘˜è¦ï¼ˆä¸ç­‰å¾…è½¬å½•ï¼‰
            segments_summary = get_segments_summary(final_segments, sample_rate)
            
            summary_message = {
                "type": "segments_summary",
                "segments": segments_summary,
                "total_segments": total_segments,
                "timestamp": time.time()
            }
            yield (json.dumps(summary_message, ensure_ascii=False) + "\n").encode("utf-8")
            
            # å¼‚æ­¥è½¬å½•ä»»åŠ¡é˜Ÿåˆ—
            transcription_tasks = []
            successful_segments = 0
            failed_segments = 0
            
            # åˆ›å»ºè½¬å½•ä»»åŠ¡ï¼ˆä¸ç«‹å³æ‰§è¡Œï¼‰
            for segment in final_segments:
                task = {
                    'segment': segment,
                    'future': None
                }
                transcription_tasks.append(task)
            
            # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
            MAX_CONCURRENT_TRANSCRIPTIONS = 3  # æ ¹æ® GPU èƒ½åŠ›è°ƒæ•´
            semaphore = asyncio.Semaphore(MAX_CONCURRENT_TRANSCRIPTIONS)
            
            async def transcribe_segment(task):
                async with semaphore:
                    segment = task['segment']
                    return await transcribe_single_segment(
                        segment, full_audio_tensor, sample_rate
                    )
            
            # å¯åŠ¨æ‰€æœ‰è½¬å½•ä»»åŠ¡
            for task in transcription_tasks:
                task['future'] = asyncio.create_task(transcribe_segment(task))
            
            # æŒ‰é¡ºåºæ”¶é›†ç»“æœï¼ˆæ˜¾ç¤ºæ›´æœ‰åºï¼‰
            for task in transcription_tasks:
                try:
                    result = await task['future']
                    if result.get('type') == 'segment_result':
                        successful_segments += 1
                    else:
                        failed_segments += 1
                    
                    # å‘é€è¿›åº¦æ›´æ–°
                    progress = round((successful_segments + failed_segments) / total_segments * 100, 1)
                    result['progress'] = progress
                    
                    yield (json.dumps(result, ensure_ascii=False) + "\n").encode("utf-8")
                    
                    # å°å»¶è¿Ÿï¼Œé¿å…å‰ç«¯è¿‡è½½
                    if total_segments > 5:
                        await asyncio.sleep(0.01)
                    
                except Exception as e:
                    logger.error(f"âŒ æ®µè½¬å½•ä»»åŠ¡å¤±è´¥: {str(e)}")
                    failed_segments += 1
            
            # å‘é€æœ€ç»ˆæ±‡æ€»
            final_summary = {
                "type": "final_summary",
                "total_segments": total_segments,
                "successful_segments": successful_segments,
                "failed_segments": failed_segments,
                "total_duration": round(total_duration, 2),
                "processing_time": round(time.time() - start_time, 2),
                "completed_at": time.time(),
                "message": "è½¬å½•å®Œæˆ"
            }
            yield (json.dumps(final_summary, ensure_ascii=False) + "\n").encode("utf-8")
        
        if stream:
            logger.info("âš¡ å¯ç”¨æµå¼å“åº”ï¼Œç«‹å³è¿”å›æ®µä¿¡æ¯")
            return StreamingResponse(
                transcribe_generator(),
                media_type="application/x-ndjson",
                headers={
                    "X-Content-Type-Options": "nosniff",
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive"
                }
            )
        else:
            # éæµå¼å¤„ç†ï¼ˆä¿æŒå…¼å®¹ï¼‰
            results = []
            async for chunk in transcribe_generator():
                results.append(json.loads(chunk.decode("utf-8").strip()))
            
            segments_result = [r for r in results if r.get("type") == "segment_result"]
            return {
                "status": "completed",
                "filename": file.filename,
                "file_size": len(file_content),
                "total_duration": round(total_duration, 2),
                "segments": segments_result,
                "total_segments": len(segments_result),
                "processing_time": round(time.time() - start_time, 2)
            }
    
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶è½¬å½•å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

# === è¾…åŠ©æ–¹æ³•ï¼ˆæå–åˆ°ç±»å¤–éƒ¨æˆ–ä¿æŒä¸ºå±€éƒ¨å‡½æ•°ï¼‰===

def cut_long_segments(raw_segments, sample_rate, total_samples, total_duration):
    """åˆ‡å‰²é•¿éŸ³é¢‘æ®µ"""
    final_segments = []
    
    for raw_segment in raw_segments:
        duration = raw_segment['duration']
        start_sample = raw_segment['start_sample']
        end_sample = raw_segment['end_sample']
        
        if duration <= AppConfig.MAX_SEGMENT_DURATION:
            final_segments.append({
                **raw_segment,
                'is_long_segment': False,
                'sub_segment_count': 1,
                'sub_segment_index': 1
            })
        else:
            # é•¿æ®µåˆ‡å‰²
            num_sub_segments = int(np.ceil(duration / AppConfig.MAX_SEGMENT_DURATION))
            samples_per_sub_segment = int(AppConfig.MAX_SEGMENT_DURATION * sample_rate)
            
            for sub_idx in range(num_sub_segments):
                sub_start_sample = start_sample + sub_idx * samples_per_sub_segment
                sub_end_sample = min(start_sample + (sub_idx + 1) * samples_per_sub_segment, end_sample, total_samples)
                sub_duration = (sub_end_sample - sub_start_sample) / sample_rate
                
                if sub_duration > 0.1:  # è·³è¿‡è¿‡çŸ­æ®µ
                    final_segments.append({
                        **raw_segment,
                        'start_sample': sub_start_sample,
                        'end_sample': sub_end_sample,
                        'start_time': sub_start_sample / sample_rate,
                        'end_time': sub_end_sample / sample_rate,
                        'duration': sub_duration,
                        'is_long_segment': True,
                        'sub_segment_count': num_sub_segments,
                        'sub_segment_index': sub_idx + 1,
                        'original_duration': duration
                    })
    
    return final_segments

def get_segments_summary(segments, sample_rate):
    """è·å–æ®µæ‘˜è¦ä¿¡æ¯"""
    return [
        {
            "segment_index": seg['segment_index'],
            "original_index": seg['original_index'],
            "start_time": round(seg['start_time'], 3),
            "end_time": round(seg['end_time'], 3),
            "duration": round(seg['duration'], 3),
            "is_long_segment": seg['is_long_segment'],
            "sub_segment_count": seg.get('sub_segment_count', 1),
            "sub_segment_index": seg.get('sub_segment_index', 1)
        }
        for seg in segments
    ]

async def transcribe_single_segment(segment, full_audio_tensor, sample_rate):
    """è½¬å½•å•ä¸ªæ®µï¼ˆå¼‚æ­¥ï¼‰"""
    segment_index = segment['segment_index']
    start_sample = segment['start_sample']
    end_sample = segment['end_sample']
    start_time = segment['start_time']
    end_time = segment['end_time']
    duration = segment['duration']
    is_long_segment = segment['is_long_segment']
    
    try:
        # ä»å®Œæ•´éŸ³é¢‘ä¸­æå–æ®µ
        segment_samples = full_audio_tensor[start_sample:end_sample]
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
        if len(segment_samples) < int(0.1 * sample_rate):  # 100ms
            raise ValueError(f"æ®µ {segment_index} æ ·æœ¬è¿‡å°‘: {len(segment_samples)}")
        
        # ç›´æ¥ä½¿ç”¨å¼ é‡ï¼ˆé¿å…ä¸´æ—¶æ–‡ä»¶ï¼‰
        segment_tensor = segment_samples.clone()
        if segment_tensor.ndim == 1:
            segment_tensor = segment_tensor.unsqueeze(0)  # è½¬ä¸º [1, samples]
        
        # è½¬å½•ï¼ˆCPU å¯†é›†å‹æ“ä½œåœ¨åå°çº¿ç¨‹ï¼‰
        loop = asyncio.get_event_loop()
        transcript = await loop.run_in_executor(
            None,
            lambda: asr_model.transcribe(segment_tensor, sampling_rate=sample_rate)
        )

        return {
            "type": "segment_result",
            "segment_index": segment_index,
            "original_index": segment['original_index'],
            "start_time": round(start_time, 3),
            "end_time": round(end_time, 3),
            "duration": round(duration, 3),
            "text": transcript.strip(),
            "processing_time": 0,  # çœŸå®æ—¶é—´åœ¨å¤–éƒ¨è®¡ç®—
            "is_long_segment": is_long_segment,
            "timestamp": time.time()
        }
        
    except Exception as e:
        logger.error(f"âŒ æ®µ {segment_index} è½¬å½•å¤±è´¥: {str(e)}")
        return {
            "type": "segment_error",
            "segment_index": segment_index,
            "original_index": segment['original_index'],
            "error": str(e),
            "is_long_segment": is_long_segment,
            "timestamp": time.time()
        }

@app.post("/vad/config")
async def update_vad_config(config: VADConfig):
    """æ›´æ–°VADé…ç½®"""
    try:
        logger.info(f"âš™ï¸ æ›´æ–° VAD é…ç½®: {config}")
        
        # æ›´æ–°å…¨å±€é…ç½®
        AppConfig.VAD_SPEECH_THRESHOLD = config.speech_threshold
        AppConfig.VAD_SMOOTHING_WINDOW = config.smoothing_window
        
        return {
            "status": "success",
            "config": config.model_dump(),
            "message": "VAD é…ç½®æ›´æ–°æˆåŠŸ"
        }
    except Exception as e:
        logger.error(f"âŒ VAD é…ç½®æ›´æ–°å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

# ======================
# WebSocket å¤„ç† 
# ======================
active_connections: Dict[str, ConnectionManager] = {}

def cleanup_client_resources(client_id: str):
    """æ¸…ç†å®¢æˆ·ç«¯ç›¸å…³èµ„æº"""
    if client_id in active_connections:
        manager = active_connections[client_id]
        try:
            manager.cleanup()
            logger.info(f"âœ… å®¢æˆ·ç«¯èµ„æºå·²æ¸…ç†: {client_id}")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å®¢æˆ·ç«¯èµ„æºå¤±è´¥ (å®¢æˆ·ç«¯: {client_id}): {str(e)}")
        finally:
            del active_connections[client_id]

def log_audio_metrics(audio_data: bytes, chunk_id: int, client_id: str):
    """è®°å½•éŸ³é¢‘æ•°æ®æŒ‡æ ‡ç”¨äºè°ƒè¯•"""
    if len(audio_data) == 0:
        logger.warning(f"ğŸ¤ å®¢æˆ·ç«¯ {client_id} éŸ³é¢‘æ•°æ®ä¸ºç©º (chunk_id: {chunk_id})")
        return
        
    # è®¡ç®—éŸ³é‡RMS
    audio_array = np.frombuffer(audio_data, dtype=np.int16)
    if len(audio_array) > 0:
        rms = np.sqrt(np.mean(np.square(audio_array.astype(np.float32))))
        peak = np.max(np.abs(audio_array))
        logger.debug(f"ğŸ¤ å®¢æˆ·ç«¯ {client_id} éŸ³é¢‘æŒ‡æ ‡ - Chunk {chunk_id}: "
                    f"å¤§å°={len(audio_data)}å­—èŠ‚, RMS={rms:.2f}, å³°å€¼={peak}")

@app.websocket("/ws/audio")
async def websocket_audio(websocket: WebSocket):
    """WebSocket å®æ—¶éŸ³é¢‘å¤„ç†ç«¯ç‚¹"""
    client_id = f"client_{int(time.time())}_{id(websocket)}"
    logger.info(f"ğŸ”Œ æ–°çš„ WebSocket è¿æ¥è¯·æ±‚: {client_id}ï¼Œæ¥æº: {websocket.client}")
    session_time = time.strftime("%Y%m%d_%H%M%S")
    debug_audio = None
    manager = None
    
    try:
        # éªŒè¯æ¥æº
        origin = websocket.headers.get('origin', '')
        logger.info(f"ğŸŒ è¿æ¥æ¥æº: {origin}")
        
        # æ¥å—è¿æ¥
        await websocket.accept()
        logger.info(f"âœ… WebSocket è¿æ¥å·²å»ºç«‹: {client_id}")
        
        # åˆ›å»ºè¿æ¥ç®¡ç†å™¨
        manager = ConnectionManager(websocket, client_id)
        active_connections[client_id] = manager
        
        # å‘é€è¿æ¥ç¡®è®¤
        await manager.send_json({
            "type": "connection_established",
            "client_id": client_id,
            "server_time": time.time(),
            "message": "WebSocket è¿æ¥æˆåŠŸ",
            "features": {
                "tiered_output": True,
                "low_latency": True,
                "vad_separation": True,
                "chunk_based_processing": True,
                "debug_audio": AppConfig.DEBUG_AUDIO_ENABLED
            },
            "configuration": {
                "audio_chunk_duration_ms": AppConfig.AUDIO_CHUNK_DURATION_MS,
                "vad_smoothing_window": AppConfig.VAD_SMOOTHING_WINDOW,
                "temporary_transcription_interval": AppConfig.TEMPORARY_TRANSCRIPTION_INTERVAL,
                "max_segment_duration": AppConfig.MAX_SEGMENT_DURATION
            }
        })
        
        # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
        if not asr_model or not vad_processor:
            error_msg = "æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•å¤„ç†éŸ³é¢‘"
            logger.error(f"âŒ {error_msg}: {client_id}")
            await manager.send_json({
                "type": "error",
                "code": 503,
                "message": error_msg
            })
            return
        
        # åˆå§‹åŒ–è°ƒè¯•éŸ³é¢‘
        if AppConfig.DEBUG_AUDIO_ENABLED:
            debug_audio = DebugAudioManager(client_id, session_time).__enter__()
            if debug_audio:
                await manager.send_json({
                    "type": "debug_audio_info",
                    "enabled": True,
                    "session_id": session_time,
                    "file_path": debug_audio.audio_path,
                    "message": "éŸ³é¢‘æ•°æ®å°†è¢«å­˜æ¡£ç”¨äºè°ƒè¯•"
                })
        
        # å¯åŠ¨VADå¤„ç†ä»»åŠ¡
        await manager.start_vad_processing()
        logger.info(f"ğŸš€ VAD å¤„ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œå®¢æˆ·ç«¯: {client_id}")
        
        # ä¸»éŸ³é¢‘æ¥æ”¶å¾ªç¯
        while manager.is_active:
            try:
                # æ£€æŸ¥è¿æ¥çŠ¶æ€
                if websocket.client_state == WebSocketState.DISCONNECTED:
                    logger.warning(f"ğŸ”Œ å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥ï¼Œåœæ­¢å¤„ç†: {client_id}")
                    break
                
                # æ¥æ”¶æ•°æ®ï¼ˆå¸¦è¶…æ—¶ï¼‰
                try:
                    # æ­£ç¡®å¤„ç†WebSocketæ¥æ”¶çš„æ•°æ®æ ¼å¼
                    message = await asyncio.wait_for(websocket.receive(), timeout=5.0)
                    manager.last_activity = time.time()
                    
                    # è®°å½•æ”¶åˆ°çš„æ¶ˆæ¯ç±»å‹
                    if 'type' in message and message['type'] == 'websocket.disconnect':
                        logger.info(f"ğŸ”Œ å®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€è¿æ¥ï¼Œä»£ç : {message.get('code', 'unknown')}")
                        break
                    
                except asyncio.TimeoutError:
                    # æ£€æŸ¥é•¿æ—¶é—´æ— æ´»åŠ¨
                    if time.time() - manager.last_activity > 30.0:
                        logger.warning(f"â° è¿æ¥è¶…æ—¶æ— æ´»åŠ¨ï¼Œå®¢æˆ·ç«¯: {client_id}")
                        await manager.send_json({
                            "type": "error",
                            "code": 408,
                            "message": "è¿æ¥è¶…æ—¶ï¼Œ30ç§’å†…æ— æ´»åŠ¨",
                            "client_id": client_id
                        })
                        break
                    continue
                
                # å¤„ç†äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ® 
                if 'bytes' in message and message['bytes'] is not None:
                    audio_data = message['bytes']
                    logger.debug(f"ğŸ§ æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(audio_data)} å­—èŠ‚ï¼Œå®¢æˆ·ç«¯: {client_id}")
                    
                    # éªŒè¯éŸ³é¢‘æ•°æ®
                    if len(audio_data) == 0:
                        logger.warning(f"âš ï¸ ç©ºéŸ³é¢‘æ•°æ®ï¼Œå®¢æˆ·ç«¯: {client_id}")
                        continue
                    
                    # æ£€æŸ¥éŸ³é¢‘æ•°æ®å¤§å°
                    expected_size = AppConfig.AUDIO_CHUNK_SIZE
                    if len(audio_data) != expected_size:
                        logger.warning(f"âš ï¸ éŸ³é¢‘æ•°æ®å¤§å°ä¸åŒ¹é…ï¼Œé¢„æœŸ: {expected_size}, å®é™…: {len(audio_data)}ï¼Œå®¢æˆ·ç«¯: {client_id}")
                        
                        # å°è¯•é‡æ–°åŒæ­¥æˆ–å¤„ç†ä¸åŒ¹é…çš„æ•°æ®
                        if len(audio_data) < expected_size:
                            # å¡«å……å°æ•°æ®
                            logger.info(f"ğŸ”§ å¡«å……å°éŸ³é¢‘æ•°æ®: {len(audio_data)} -> {expected_size} å­—èŠ‚")
                            padded_data = bytearray(audio_data)
                            padded_data.extend(b'\x00' * (expected_size - len(audio_data)))
                            audio_data = bytes(padded_data)
                        elif len(audio_data) > expected_size:
                            # å¤„ç†å¤§æ•°æ® - å¯èƒ½æ˜¯å¤šä¸ªç‰‡æ®µ
                            logger.info(f"ğŸ”§ å¤„ç†å¤§æ•°æ®å—: {len(audio_data)} å­—èŠ‚ï¼Œå¯èƒ½åŒ…å« {len(audio_data) // expected_size + 1} ä¸ªç‰‡æ®µ")
                            
                            # å¤„ç†å®Œæ•´çš„ç‰‡æ®µ
                            for i in range(0, len(audio_data) - expected_size + 1, expected_size):
                                chunk = audio_data[i:i+expected_size]
                                if len(chunk) == expected_size:
                                    await manager.process_audio_chunk(chunk, debug_audio)
                                    log_audio_metrics(chunk, manager.last_chunk_id, client_id)
                            
                            # å‰©ä½™æ•°æ®ä¸è¶³ä¸€ä¸ªç‰‡æ®µ
                            remaining = len(audio_data) % expected_size
                            if remaining > 0:
                                logger.info(f"ğŸ”§ å‰©ä½™ {remaining} å­—èŠ‚ï¼Œç­‰å¾…ä¸‹ä¸€æ‰¹æ•°æ®å®Œæˆç‰‡æ®µ")
                            continue
                    
                    # å¤„ç†å•ä¸ªéŸ³é¢‘ç‰‡æ®µ
                    await manager.process_audio_chunk(audio_data, debug_audio)
                    log_audio_metrics(audio_data, manager.last_chunk_id, client_id)
                
                # å¤„ç†æ–‡æœ¬æ§åˆ¶æ¶ˆæ¯
                elif 'text' in message and message['text'] is not None:
                    try:
                        # æ­£ç¡®è§£ææ–‡æœ¬æ¶ˆæ¯
                        text_data = message['text']
                        msg_data = json.loads(text_data)
                        msg_type = msg_data.get('type', 'unknown')
                        logger.debug(f"âš™ï¸ æ”¶åˆ°æ§åˆ¶æ¶ˆæ¯: {msg_type}, å®¢æˆ·ç«¯: {client_id}")
                        
                        if msg_type == 'close':
                            logger.info(f"ğŸ‘‹ å®¢æˆ·ç«¯è¯·æ±‚å…³é—­è¿æ¥, å®¢æˆ·ç«¯: {client_id}")
                            break
                            
                        elif msg_type == 'ping':
                            await manager.send_json({
                                "type": "pong",
                                "timestamp": time.time(),
                                "client_id": client_id
                            })
                            logger.debug(f"ğŸ“ å·²å›åº” pingï¼Œå®¢æˆ·ç«¯: {client_id}")
                            
                        elif msg_type == 'get_state':
                            state = {
                                "type": "connection_state",
                                "client_id": client_id,
                                "buffer_size": len(manager.buffer_manager.chunk_buffer),
                                "active_segment": manager.buffer_manager.current_segment is not None,
                                "vad_state": manager.vad_processor.is_speaking_state(),
                                "last_chunk_id": manager.last_chunk_id,
                                "timestamp": time.time(),
                                "audio_config": {
                                    "chunk_duration_ms": AppConfig.AUDIO_CHUNK_DURATION_MS,
                                    "sample_rate": AppConfig.AUDIO_SAMPLE_RATE,
                                    "bytes_per_sample": 2
                                }
                            }
                            await manager.send_json(state)
                            logger.debug(f"ğŸ“Š å·²å‘é€è¿æ¥çŠ¶æ€ï¼Œå®¢æˆ·ç«¯: {client_id}")
                            
                        elif msg_type == 'vad_config':
                            config = msg_data.get('config', {})
                            logger.info(f"ğŸ”§ æ”¶åˆ° VAD é…ç½®æ›´æ–°è¯·æ±‚: {config}, å®¢æˆ·ç«¯: {client_id}")
                            # è½¬å‘åˆ°VADé…ç½®ç«¯ç‚¹
                            vad_config = VADConfig(**config)
                            response = await update_vad_config(vad_config)
                            await manager.send_json({
                                "type": "config_updated",
                                "timestamp": time.time(),
                                "client_id": client_id,
                                "config": config
                            })
                            
                        else:
                            logger.warning(f"â“ æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg_type}, å®¢æˆ·ç«¯: {client_id}")
                            await manager.send_json({
                                "type": "error",
                                "code": 400,
                                "message": f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg_type}",
                                "client_id": client_id
                            })
                    except json.JSONDecodeError as e:
                        logger.error(f"âŒ JSON è§£æå¤±è´¥: {str(e)}, åŸå§‹æ•°æ®: {text_data}, å®¢æˆ·ç«¯: {client_id}")
                        await manager.send_json({
                            "type": "error",
                            "code": 400,
                            "message": f"æ— æ•ˆçš„ JSON æ ¼å¼: {str(e)}",
                            "client_id": client_id
                        })
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†æ§åˆ¶æ¶ˆæ¯å¤±è´¥: {str(e)}\n{traceback.format_exc()}, å®¢æˆ·ç«¯: {client_id}")
                        await manager.send_json({
                            "type": "error",
                            "code": 500,
                            "message": f"å¤„ç†æ§åˆ¶æ¶ˆæ¯å¤±è´¥: {str(e)}",
                            "client_id": client_id
                        })
                else:
                    # è®°å½•æœªçŸ¥æ¶ˆæ¯æ ¼å¼
                    logger.debug(f"ğŸ” æœªçŸ¥æ¶ˆæ¯æ ¼å¼ï¼Œå®¢æˆ·ç«¯: {client_id}, æ¶ˆæ¯: {message}")
            
            except WebSocketDisconnect as e:
                logger.info(f"ğŸ”Œ å®¢æˆ·ç«¯æ­£å¸¸æ–­å¼€è¿æ¥ (code={e.code}), å®¢æˆ·ç«¯: {client_id}")
                break
            except Exception as e:
                logger.error(f"âŒ WebSocket å¤„ç†é”™è¯¯ (å®¢æˆ·ç«¯: {client_id}): {str(e)}\n{traceback.format_exc()}")
                await manager.send_json({
                    "type": "error",
                    "code": 500,
                    "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}",
                    "client_id": client_id
                })
    
    except Exception as e:
        logger.critical(f"âŒ WebSocket æœªå¤„ç†å¼‚å¸¸ (å®¢æˆ·ç«¯: {client_id}): {str(e)}\n{traceback.format_exc()}")
    finally:
        logger.info(f"ğŸ§¹ æœ€ç»ˆæ¸…ç†å®¢æˆ·ç«¯èµ„æº: {client_id}")
        
        # æ¸…ç†è¿æ¥
        if client_id in active_connections:
            cleanup_client_resources(client_id)
        
        # æ¸…ç†è°ƒè¯•éŸ³é¢‘
        if debug_audio:
            debug_audio.cleanup()
        
        # ç¡®ä¿è¿æ¥å…³é—­
        try:
            if websocket.client_state != WebSocketState.DISCONNECTED:
                await websocket.close(code=1000, reason="Normal closure")
        except Exception as e:
            logger.warning(f"âš ï¸ å…³é—­è¿æ¥æ—¶å‡ºé”™ (å®¢æˆ·ç«¯: {client_id}): {str(e)}")

# ======================
# åº”ç”¨å¯åŠ¨
# ======================
if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨ FastAPI æœåŠ¡å™¨...")
    logger.info(f"ğŸ“ è®¿é—®åœ°å€: http{'s' if AppConfig.USE_HTTPS else ''}://{AppConfig.HOST}:{AppConfig.PORT}/docs")
    logger.info(f"ğŸ“ WebSocket åœ°å€: ws{'s' if AppConfig.USE_HTTPS else ''}://{AppConfig.HOST}:{AppConfig.PORT}/ws/audio")
    logger.info(f"âš™ï¸ æ ¸å¿ƒé…ç½®:")
    logger.info(f"  - éŸ³é¢‘å¤„ç†: {AppConfig.AUDIO_CHUNK_DURATION_MS}ms/ç‰‡æ®µ")
    logger.info(f"  - VADå¤„ç†: {AppConfig.VAD_SMOOTHING_WINDOW}ç‰‡æ®µå¹³æ»‘çª—å£")
    logger.info(f"  - ä¸´æ—¶è½¬å½•: æ¯{AppConfig.TEMPORARY_TRANSCRIPTION_INTERVAL}ç‰‡æ®µ(1ç§’)")
    logger.info(f"  - æœ€å¤§ç¼“å†²åŒº: {AppConfig.MAX_AUDIO_BUFFER_SECONDS}ç§’")
    logger.info(f"  - è®¾å¤‡: {AppConfig.DEVICE}")
    logger.info(f"ğŸ” è°ƒè¯•éŸ³é¢‘: {'å¯ç”¨' if AppConfig.DEBUG_AUDIO_ENABLED else 'ç¦ç”¨'}")
    logger.info("ğŸ›¡ï¸ CORS é…ç½®: å…è®¸æ‰€æœ‰æ¥æº")
    
    uvicorn_config = {
        "app": app,
        "host": AppConfig.HOST,
        "port": AppConfig.PORT,
        "reload": False,
        "log_level": AppConfig.LOG_LEVEL.lower(),
        "workers": 1  # WebSocket ä¸æ”¯æŒå¤š worker
    }
    
    if AppConfig.USE_HTTPS:
        logger.info("ğŸ”’ å¯ç”¨ HTTPS æ¨¡å¼")
        uvicorn_config.update({
            "ssl_certfile": AppConfig.SSL_CERT,
            "ssl_keyfile": AppConfig.SSL_KEY
        })
    else:
        logger.warning("âš ï¸  ä½¿ç”¨ HTTP æ¨¡å¼ (ç”Ÿäº§ç¯å¢ƒå»ºè®®å¯ç”¨ HTTPS)")
    
    uvicorn.run(**uvicorn_config)